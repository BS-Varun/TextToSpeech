{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgIXN9u9pQPywDZxCg/Gc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BS-Varun/TextToSpeech/blob/main/tacotron_tts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFB-nJUXrSDo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4d2LXHbC-Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38a2dad-67f0-451e-9bb7-99339ceb1ba1"
      },
      "source": [
        "! git clone https://github.com/Emotional-Text-to-Speech/pytorch-dc-tts\n",
        "! git clone --recursive https://github.com/Emotional-Text-to-Speech/tacotron_pytorch.git\n",
        "! cd \"tacotron_pytorch/\" && pip install -e .\n",
        "! pip install unidecode\n",
        "! pip install gdown\n",
        "! mkdir trained_models\n",
        "\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1rmhtEl3N3kAfnQM6J0vDGSCCHlHLK6kw'\n",
        "output = 'trained_models/angry_dctts.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "url = 'https://drive.google.com/uc?id=1bP0eJ6z4onr2klolzU17Y8SaNspxQjF-'\n",
        "output = 'trained_models/neutral_dctts.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "url = 'https://drive.google.com/uc?id=1WWE9zxS3FRgD0Y5yIdNmLY9-t5gnBsNt'\n",
        "output = 'trained_models/ssrn.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "url = 'https://drive.google.com/uc?id=1N6Ykrd1IaPiNdos_iv0J6JbY2gBDghod'\n",
        "output = 'trained_models/disgust_tacotron.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "url = 'https://drive.google.com/uc?id=15m0PZ8xaBocb_6wDjAU6S4Aunbr3TKkM'\n",
        "output = 'trained_models/amused_tacotron.pth'\n",
        "gdown.download(url, output, quiet=False)\n",
        "url = 'https://drive.google.com/uc?id=1D6HGWYWvhdvLWQt4uOYqdmuVO7ZVLWNa'\n",
        "output = 'trained_models/sleepiness_tacotron.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-dc-tts'...\n",
            "remote: Enumerating objects: 1904, done.\u001b[K\n",
            "remote: Counting objects: 100% (319/319), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 1904 (delta 91), reused 302 (delta 86), pack-reused 1585\u001b[K\n",
            "Receiving objects: 100% (1904/1904), 277.55 MiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (226/226), done.\n",
            "Cloning into 'tacotron_pytorch'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Total 150 (delta 0), reused 0 (delta 0), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (150/150), 21.19 MiB | 14.64 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Submodule 'lib/tacotron' (https://github.com/r9y9/tacotron) registered for path 'lib/tacotron'\n",
            "Cloning into '/content/dl-for-emo-tts/tacotron_pytorch/lib/tacotron'...\n",
            "remote: Enumerating objects: 212, done.        \n",
            "remote: Total 212 (delta 0), reused 0 (delta 0), pack-reused 212        \n",
            "Receiving objects: 100% (212/212), 62.01 KiB | 4.43 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n",
            "Submodule path 'lib/tacotron': checked out '0987cedd0d6a6909749c594ca978ac4e11ae79ae'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/dl-for-emo-tts/tacotron_pytorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tacotron-pytorch==0.0.1+e6b1a39) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tacotron-pytorch==0.0.1+e6b1a39) (1.10.1)\n",
            "Installing collected packages: tacotron-pytorch\n",
            "  Running setup.py develop for tacotron-pytorch\n",
            "Successfully installed tacotron-pytorch-0.0.1+e6b1a39\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1rmhtEl3N3kAfnQM6J0vDGSCCHlHLK6kw \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1bP0eJ6z4onr2klolzU17Y8SaNspxQjF- \n",
            "\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1WWE9zxS3FRgD0Y5yIdNmLY9-t5gnBsNt \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1N6Ykrd1IaPiNdos_iv0J6JbY2gBDghod \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=15m0PZ8xaBocb_6wDjAU6S4Aunbr3TKkM \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1D6HGWYWvhdvLWQt4uOYqdmuVO7ZVLWNa \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/soobinseo/Tacotron-2.git\n",
        "%cd Tacotron-2/tacotron_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smg8iYgLX2oc",
        "outputId": "d0e3ceec-e5e4-4465-d219-44332dfe11a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tacotron-2'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'Tacotron-2/tacotron_pytorch'\n",
            "/content/dl-for-emo-tts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Emotional-Text-to-Speech/dl-for-emo-tts.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ogmIzC7rNn",
        "outputId": "9910344c-ae6d-43a7-d43d-8a7cc2f2cd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dl-for-emo-tts'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 86 (delta 14), reused 0 (delta 0), pack-reused 60\u001b[K\n",
            "Unpacking objects: 100% (86/86), 5.32 MiB | 8.16 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dl-for-emo-tts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f_fF-H08I1K",
        "outputId": "8c055bd1-eb44-4ade-83a4-c8f84fd8813f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dl-for-emo-tts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode inflect\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svc_yimM8dzk",
        "outputId": "25770f16-b7aa-4020-b41b-c1ae75105ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (6.0.4)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect) (1.10.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect) (4.5.0)\n",
            "Installing collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-dc-tts"
      ],
      "metadata": {
        "id": "KH2px1VWFsqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa.display\n",
        "import IPython\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import widgets\n",
        "sys.path.append('pytorch-dc-tts/')\n",
        "sys.path.append('pytorch-dc-tts/models')\n",
        "sys.path.append(\"tacotron_pytorch/\")\n",
        "sys.path.append(\"tacotron_pytorch/lib/tacotron\")\n",
        "from text import text_to_sequence, symbols\n",
        "\n",
        "from tacotron_pytorch import Tacotron\n",
        "from synthesis import tts as _tts\n",
        "from tacotron_pytorch import Tacotron\n",
        "from synthesis import tts as _tts\n",
        "\n",
        "# Set up the environment\n",
        "%tensorflow_version 1.x\n",
        "%pylab inline\n",
        "rcParams[\"figure.figsize\"] = (10, 5)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up the paths\n",
        "\n",
        "\n",
        "# Load the models\n",
        "model_checkpoint = 'trained_models/ssrn.pth'\n",
        "model = Tacotron(n_vocab=len(symbols), embedding_dim=256, mel_dim=80, linear_dim=1025, r=5, padding_idx=None, use_memory_mask=False)\n",
        "load_checkpoint(model_checkpoint, model, None)\n",
        "\n",
        "def visualize(alignment, spectrogram, emotion):\n",
        "    label_fontsize = 16\n",
        "    tb = widgets.TabBar(['Alignment', 'Spectrogram'], location='top')\n",
        "    with tb.output_to('Alignment'):\n",
        "        imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n",
        "        xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n",
        "        ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n",
        "    with tb.output_to('Spectrogram'):\n",
        "        librosa.display.specshow(spectrogram.T, sr=fs, hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
        "        xlabel(\"Time\", fontsize=label_fontsize)\n",
        "        ylabel(\"Hz\", fontsize=label_fontsize)\n",
        "\n",
        "def tts_dctts(text):\n",
        "    from text2mel import Text2Mel\n",
        "    from ssrn import SSRN\n",
        "    from audio import save_to_wav, spectrogram2wav\n",
        "    from utils import get_last_checkpoint_file_name, load_checkpoint_test, save_to_png, load_checkpoint\n",
        "    from datasets.emovdb import vocab, get_test_data\n",
        "\n",
        "    torch.set_grad_enabled(False)\n",
        "    text2mel = Text2Mel(vocab).eval()\n",
        "    ssrn = SSRN().eval()\n",
        "    load_checkpoint('trained_models/ssrn.pth', ssrn, None)\n",
        "\n",
        "    sentences = [text]\n",
        "    max_N = len(text)\n",
        "    L = torch.from_numpy(get_test_data(sentences, max_N))\n",
        "    zeros = torch.from_numpy(np.zeros((1, 80, 1), np.float32))\n",
        "    Y = zeros\n",
        "    A = None\n",
        "\n",
        "    for t in range(210):\n",
        "        _, Y_t, A = text2mel(L, Y, monotonic_attention=True)\n",
        "        Y = torch.cat((zeros, Y_t), -1)\n",
        "        _, attention = torch.max(A[0, :, -1], 0)\n",
        "        attention = attention.item()\n",
        "        if L[0, attention] == vocab.index('E'):  # EOS\n",
        "            break\n",
        "\n",
        "    _, Z = ssrn(Y)\n",
        "    Y = Y.cpu().detach().numpy()\n",
        "    A = A.cpu().detach().numpy()\n",
        "    Z = Z.cpu().detach().numpy()\n",
        "\n",
        "    return spectrogram2wav(Z[0, :, :].T), A[0, :, :], Y[0, :, :]\n",
        "\n",
        "def tts_tacotron(text):\n",
        "    waveform, alignment, spectrogram = _tts(model, text)\n",
        "    return waveform, alignment, spectrogram\n",
        "\n",
        "def present(waveform, emotion, figures=False):\n",
        "    if figures != False:\n",
        "        visualize(figures[0], figures[1], emotion)\n",
        "    display(Audio(waveform, rate=fs))\n",
        "\n",
        "fs = 20000\n",
        "hop_length = 250\n",
        "model.decoder.max_decoder_steps = 200\n",
        "\n",
        "# Example usage with DC-TTS\n",
        "text = \"Hello, how are you?\"\n",
        "waveform, alignment, spectrogram = tts_dctts(text)\n",
        "present(waveform, \"Neutral\", (alignment, spectrogram))\n",
        "\n",
        "# Example usage with Tacotron\n",
        "text = \"Hello, how are you?\"\n",
        "waveform, alignment, spectrogram = tts_tacotron(text)\n",
        "present(waveform, \"Neutral\", (alignment, spectrogram))\n"
      ],
      "metadata": {
        "id": "LAZEWSNx9M2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select the emotion and type the text\n",
        "\n",
        "%pylab inline\n",
        "\n",
        "Emotion = \"Neutral\" #@param [\"Neutral\", \"Angry\", \"Disgust\", \"Sleepiness\", \"Amused\"]\n",
        "Text = 'I am exhausted.' #@param {type:\"string\"}\n",
        "\n",
        "wav, align, mel = None, None, None\n",
        "\n",
        "if Emotion == \"Neutral\":\n",
        "  load_checkpoint('trained_models/'+Emotion.lower()+'_dctts.pth', text2mel, None)\n",
        "  wav, align, mel = tts_dctts(text2mel, ssrn, Text)\n",
        "elif Emotion == \"Angry\":\n",
        "  load_checkpoint_test('trained_models/'+Emotion.lower()+'_dctts.pth', text2mel, None)\n",
        "  wav, align, mel = tts_dctts(text2mel, ssrn, Text)\n",
        "  # wav = wav.T\n",
        "elif Emotion == \"Disgust\" or Emotion == \"Amused\" or Emotion == \"Sleepiness\":\n",
        "  checkpoint = torch.load('trained_models/'+Emotion.lower()+'_tacotron.pth', map_location=torch.device('cpu'))\n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "  wav, align, mel = tts_tacotron(model, Text)\n",
        "\n",
        "present(wav, Emotion, (align,mel))"
      ],
      "metadata": {
        "id": "1FL4dykzQACO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}